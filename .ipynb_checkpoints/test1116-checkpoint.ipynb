{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b7d4b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './realdata_result/RTER.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2096/2474341858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mlog_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             logs= \"{},{},{},{}\\n\".format(data_name,\n\u001b[1;32m     93\u001b[0m                                           \u001b[0mmse_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_end\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './realdata_result/RTER.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import wilcoxon\n",
    "from RTER import RegressionTree\n",
    "from comparison.ensemble import RegressionTreeBoosting, RegressionTreeEnsemble\n",
    "from comparison.EKNN import EKNN\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from time import time\n",
    "\n",
    "\n",
    "data_file_dir = \"./data/\"\n",
    "#data_file_name_seq = ['ionosphere.csv','adult.csv','abalone.csv', 'australian.csv', 'breast-cancer.csv', 'credit.csv', 'parkinsons.csv', 'winequality-red.csv', 'winequality-white.csv', 'winequality.csv']\n",
    "data_file_name_seq = ['possum.csv']\n",
    "#data_file_name_seq=[\"lympho.csv\",\"cardio.csv\", \"thyroid.csv\",\"vowels.csv\", \"glass.csv\", \"musk.csv\",\"letter.csv\", \"pima.csv\", \"satellite.csv\", \"pendigits.csv\", \"yeast.csv\", \"heart.csv\"]\n",
    "#data_file_name_seq=['ionosphere.csv','adult.csv', 'winequality.csv']\n",
    "\n",
    "log_file_dir = \"./realdata_result/\"\n",
    "\n",
    "def anll(pdf):\n",
    "    return -np.log(pdf).mean()\n",
    "\n",
    "\n",
    "for data_file_name in data_file_name_seq:\n",
    "    # load dataset\n",
    "    data_file_path = os.path.join(data_file_dir, data_file_name)\n",
    "    data = pd.read_csv(data_file_path)\n",
    "    #data = np.array(data)\n",
    "    # dataset status\n",
    "    data_name = os.path.splitext(data_file_name)[0]\n",
    "    if data_name == 'possum':\n",
    "        data = data.drop(columns=['case','Pop','sex'])\n",
    "        #print(data)\n",
    "        #import pdb;pdb.set_trace()\n",
    "\n",
    "    num_samples = data.shape[0]\n",
    "    num_features = data.shape[1]-1\n",
    "    colname = list(data.columns)\n",
    "    # transformation\n",
    "    scaler = MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    \n",
    "    data = data[np.logical_not(np.isnan(data).any(axis=1))]\n",
    "    #import pdb;pdb.set_trace()\n",
    "\n",
    "    #\n",
    "    repeat_times = 5\n",
    "\n",
    "\n",
    "    ##################################缩放的时候是否把训练集测试集同时缩放了？\n",
    "    for i in range(repeat_times):\n",
    "\n",
    "        # pca\n",
    "        train_X, test_X = train_test_split(data, train_size=0.7, test_size=0.3, random_state= i )\n",
    "        if data_name == 'possum':\n",
    "            #df_train = pd.DataFrame(train_X, columns = colname)\n",
    "            train_ys = train_X[:,2]\n",
    "            train_xs = np.delete(train_X,2, axis=1)\n",
    "            #df_test = pd.DataFrame(test_X, columns = colname)\n",
    "            test_ys = test_X[:,2]\n",
    "            test_xs = np.delete(test_X,2, axis=1)\n",
    "\n",
    "        #import pdb;pdb.set_trace()\n",
    "\n",
    "        # estimation\n",
    "\n",
    "        \n",
    "        time_start=time()\n",
    "        parameters={\"truncate_ratio_low\":[0], \"truncate_ratio_up\":[0.4,0.6,0.8 ],\n",
    "           \"min_samples_split\":[10,30], \"max_depth\":[1,2,4,6],\n",
    "           \"order\":[0,1,3,6],\"splitter\":[\"varreduction\"],\n",
    "            \"estimator\":[\"pointwise_extrapolation_estimator\"],\n",
    "           \"r_range_low\":[0],\"r_range_up\":[1],\n",
    "           \"step\":[1,2,4,8],\"lamda\":[0.001,0.01,0.1,1,5]}\n",
    "        RTER_model=RegressionTree(min_samples_split=30, max_depth=3,parallel_jobs=0)\n",
    "        RTER_model.fit(train_xs, train_ys) ##############\n",
    "        mse_score=-RTER_model.score(test_xs, test_ys)\n",
    "        time_end=time()\n",
    "     \n",
    "        log_file_name = \"{}.csv\".format(\"RTER\")\n",
    "        log_file_path = os.path.join(log_file_dir, log_file_name)\n",
    "        \n",
    "        with open(log_file_path, \"a\") as f:\n",
    "            logs= \"{},{},{},{}\\n\".format(data_name,\n",
    "                                          mse_score, time_end-time_start,\n",
    "                                          i)\n",
    "            f.writelines(logs)\n",
    "        \n",
    "        # boosting\n",
    "        time_start=time()\n",
    "        parameters={\"rho\":[0.01,0.05,0.1], \"boost_num\":[50,100,200], \"min_samples_split\":[10], \"max_depth\":[2,5,8],\"splitter\":[\"maxedge\"]}\n",
    "        cv_model_boosting=GridSearchCV(estimator=RegressionTreeBoosting(),param_grid=parameters, cv=10, n_jobs=-1)\n",
    "        cv_model_boosting.fit(train_xs, train_ys)\n",
    "        boosting_model = cv_model_boosting.best_estimator_\n",
    "        mse_score= - boosting_model.score(test_xs, test_ys)\n",
    "        log_file_name = \"{}.csv\".format(\"boosting\")\n",
    "        log_file_path = os.path.join(log_file_dir, log_file_name)\n",
    "        time_end=time()\n",
    "        \n",
    "        log_file_name = \"{}.csv\".format(\"boosting\")\n",
    "        log_file_path = os.path.join(log_file_dir, log_file_name)\n",
    "        \n",
    "        with open(log_file_path, \"a\") as f:\n",
    "            logs= \"{},{},{},{}\\n\".format(data_name,\n",
    "                                          mse_score, time_end-time_start,\n",
    "                                          i)\n",
    "            f.writelines(logs)\n",
    "         \n",
    "        # ensemble\n",
    "        time_start=time()\n",
    "        parameters={ \"ensemble_num\":[50,100,200], \"min_samples_split\":[10], \"max_depth\":[2,5,8],\"splitter\":[\"maxedge\"]}\n",
    "        cv_model_ensemble=GridSearchCV(estimator=RegressionTreeEnsemble(),param_grid=parameters, cv=10, n_jobs=-1)\n",
    "        cv_model_ensemble.fit(train_xs, train_ys)\n",
    "        ensemble_model = cv_model_ensemble.best_estimator_\n",
    "        mse_score= - ensemble_model.score(test_xs, test_ys)\n",
    "        time_end=time()\n",
    "        \n",
    "        log_file_name = \"{}.csv\".format(\"ensemble\")\n",
    "        log_file_path = os.path.join(log_file_dir, log_file_name)\n",
    "        \n",
    "        with open(log_file_path, \"a\") as f:\n",
    "            logs= \"{},{},{},{}\\n\".format(data_name,\n",
    "                                          mse_score, time_end-time_start,\n",
    "                                          i)\n",
    "            f.writelines(logs)\n",
    "         \n",
    "        # GBRT\n",
    "        time_start=time()\n",
    "        parameters= {\"n_estimators\":[500,1000,2000], \"learning_rate\":[0.01,0.05]}\n",
    "        cv_model_GBRT=GridSearchCV(estimator=GradientBoostingRegressor(),param_grid=parameters, cv=10, n_jobs=-1)\n",
    "        cv_model_GBRT.fit(train_xs, train_ys)\n",
    "        model_GBRT = cv_model_GBRT.best_estimator_\n",
    "        model_GBRT.fit(train_xs, train_ys.ravel())\n",
    "        y_hat=model_GBRT.predict(test_xs)\n",
    "        mse_score = MSE(y_hat, test_ys)\n",
    "        time_end=time()\n",
    "        \n",
    "        log_file_name = \"{}.csv\".format(\"GBRT\")\n",
    "        log_file_path = os.path.join(log_file_dir, log_file_name)\n",
    "        \n",
    "        with open(log_file_path, \"a\") as f:\n",
    "            logs= \"{},{},{},{},{},{}\\n\".format(data_name,\n",
    "                                          mse_score, time_end-time_start,\n",
    "                                          i)\n",
    "            f.writelines(logs)\n",
    "            \n",
    "            \n",
    "        # RF\n",
    "        time_start=time()\n",
    "        parameters = {\"n_estimators\":[10,100,200]}\n",
    "        cv_model_RFR = GridSearchCV(estimator=RandomForestRegressor(),param_grid=parameters, cv=10, n_jobs=-1) \n",
    "        cv_model_RFR.fit(train_xs, train_ys)\n",
    "        model_RFR = cv_model_RFR.best_estimator_\n",
    "        model_RFR.fit(train_xs, train_ys)\n",
    "        y_hat=model_RFR.predict(test_xs)\n",
    "        mse_score = MSE(y_hat, test_ys)\n",
    "        time_end=time()\n",
    "        \n",
    "        log_file_name = \"{}.csv\".format(\"RFR\")\n",
    "        log_file_path = os.path.join(log_file_dir, log_file_name)\n",
    "        \n",
    "        with open(log_file_path, \"a\") as f:\n",
    "            logs= \"{},{},{},{}\\n\".format(data_name,\n",
    "                                          mse_score, time_end-time_start,\n",
    "                                          i)\n",
    "            f.writelines(logs)\n",
    "            \n",
    "            \n",
    "        '''   \n",
    "        # EKNN\n",
    "        time_start=time()\n",
    "        parameters = {\"V\":[4,8,12,16], \"C\":[1,3,5,7,9,11],\"alpha\":[0.01,0.05,0.1]}\n",
    "        cv_model_EKNN = GridSearchCV(estimator=EKNN(),param_grid=parameters, cv=10, n_jobs=-1) \n",
    "        cv_model_EKNN.fit(X_train, Y_train)\n",
    "        model_EKNN = cv_model_EKNN.best_estimator_\n",
    "        model_EKNN.fit(X_train, Y_train)\n",
    "        y_hat=model_EKNN.predict(X_test)\n",
    "        mse_score = MSE(y_hat, Y_test)\n",
    "        time_end=time()\n",
    "        \n",
    "        log_file_name = \"{}.csv\".format(\"EKNN\")\n",
    "        log_file_path = os.path.join(log_file_dir, log_file_name)\n",
    "        \n",
    "        with open(log_file_path, \"a\") as f:\n",
    "            logs= \"{},{},{},{},{},{}\\n\".format(distribution_index,\n",
    "                                          mse_score, time_end-time_start,\n",
    "                                          iterate,n_train,n_test)\n",
    "            f.writelines(logs)\n",
    "        \n",
    "        '''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd12d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83333333, 0.25      , 0.24731183, 0.25581395, 0.36363636,\n",
       "        0.13068182, 0.20754717, 0.7       , 0.3       , 0.23333333],\n",
       "       [1.        , 0.375     , 0.35483871, 0.62790698, 0.5       ,\n",
       "        0.23863636, 0.32075472, 0.42      , 0.5       , 0.4       ],\n",
       "       [0.66666667, 0.        , 0.12903226, 0.25581395, 0.27272727,\n",
       "        0.09659091, 0.13207547, 0.26      , 0.35      , 0.33333333],\n",
       "       [0.5       , 0.125     , 0.70967742, 0.81395349, 0.54545455,\n",
       "        0.69318182, 0.28930818, 0.72      , 0.85      , 0.73333333],\n",
       "       [0.        , 0.375     , 0.3655914 , 0.55813953, 0.22727273,\n",
       "        0.73295455, 0.79874214, 0.5       , 0.5       , 0.33333333],\n",
       "       [0.        , 0.5       , 0.29032258, 0.72093023, 0.27272727,\n",
       "        0.74431818, 0.85534591, 0.48      , 0.6       , 0.46666667],\n",
       "       [0.5       , 0.125     , 0.41397849, 0.60465116, 0.63636364,\n",
       "        0.15909091, 0.42138365, 0.32      , 0.4       , 0.33333333],\n",
       "       [0.66666667, 0.375     , 0.40860215, 0.46511628, 0.40909091,\n",
       "        0.25      , 0.23899371, 0.74      , 0.55      , 0.3       ],\n",
       "       [0.83333333, 0.        , 0.05376344, 0.27906977, 0.40909091,\n",
       "        0.15340909, 0.25157233, 0.08      , 0.1       , 0.2       ],\n",
       "       [0.        , 0.625     , 0.40860215, 0.76744186, 0.40909091,\n",
       "        0.69318182, 0.68553459, 0.64      , 0.65      , 0.53333333],\n",
       "       [0.66666667, 0.5       , 0.39784946, 0.62790698, 0.54545455,\n",
       "        0.44886364, 0.08805031, 0.24      , 0.7       , 0.9       ],\n",
       "       [0.16666667, 0.25      , 0.3172043 , 0.27906977, 0.18181818,\n",
       "        0.63636364, 0.86163522, 0.36      , 0.5       , 0.43333333],\n",
       "       [0.16666667, 0.125     , 0.29569892, 0.27906977, 0.        ,\n",
       "        0.66477273, 0.57232704, 0.12      , 0.7       , 0.4       ],\n",
       "       [0.        , 0.125     , 0.33870968, 0.48837209, 0.36363636,\n",
       "        0.60795455, 0.81132075, 0.46      , 0.65      , 0.53333333],\n",
       "       [0.        , 0.375     , 0.32258065, 0.51162791, 0.22727273,\n",
       "        0.72159091, 0.69811321, 0.32      , 0.6       , 0.46666667],\n",
       "       [0.        , 0.125     , 0.30645161, 0.69767442, 0.36363636,\n",
       "        0.76136364, 0.94968553, 0.5       , 0.6       , 0.46666667],\n",
       "       [0.16666667, 0.25      , 0.22043011, 0.09302326, 0.        ,\n",
       "        0.13636364, 0.68553459, 0.2       , 0.35      , 0.53333333],\n",
       "       [0.16666667, 0.        , 0.08064516, 0.        , 0.18181818,\n",
       "        0.47727273, 0.82389937, 0.04      , 0.3       , 0.        ],\n",
       "       [0.        , 0.        , 0.25806452, 0.72093023, 0.31818182,\n",
       "        0.73295455, 0.83647799, 0.28      , 0.8       , 0.46666667],\n",
       "       [1.        , 0.375     , 0.30645161, 0.37209302, 0.54545455,\n",
       "        0.35227273, 0.46540881, 0.24      , 0.3       , 0.53333333],\n",
       "       [0.66666667, 0.625     , 0.34408602, 0.62790698, 0.54545455,\n",
       "        0.21590909, 0.37735849, 0.48      , 0.35      , 0.23333333],\n",
       "       [0.        , 0.875     , 0.55913978, 0.65116279, 0.36363636,\n",
       "        0.80681818, 0.89308176, 0.48      , 0.6       , 0.73333333],\n",
       "       [0.16666667, 0.375     , 0.42473118, 0.46511628, 0.31818182,\n",
       "        0.61931818, 0.95597484, 0.72      , 0.6       , 0.7       ],\n",
       "       [0.        , 0.25      , 0.32258065, 0.60465116, 0.27272727,\n",
       "        0.82954545, 0.72327044, 0.24      , 0.2       , 0.46666667],\n",
       "       [0.5       , 0.75      , 0.69892473, 0.76744186, 1.        ,\n",
       "        0.625     , 0.35849057, 0.94      , 0.8       , 0.76666667],\n",
       "       [0.        , 0.5       , 0.30107527, 0.79069767, 0.31818182,\n",
       "        0.64772727, 0.67295597, 0.5       , 0.6       , 0.53333333],\n",
       "       [0.16666667, 0.75      , 0.5       , 0.60465116, 0.27272727,\n",
       "        0.79545455, 0.73584906, 0.42      , 0.35      , 0.73333333],\n",
       "       [0.        , 0.125     , 0.26344086, 0.41860465, 0.18181818,\n",
       "        0.83522727, 0.83018868, 0.68      , 0.5       , 0.46666667],\n",
       "       [0.5       , 0.25      , 0.61827957, 0.86976744, 0.54545455,\n",
       "        0.47727273, 0.40880503, 0.72      , 0.55      , 0.43333333],\n",
       "       [0.        , 1.        , 0.38709677, 0.6744186 , 0.63636364,\n",
       "        0.96022727, 0.6918239 , 0.42      , 0.9       , 0.6       ],\n",
       "       [0.        , 0.375     , 0.36021505, 0.88372093, 0.63636364,\n",
       "        0.82386364, 0.73584906, 0.42      , 0.6       , 0.6       ],\n",
       "       [0.66666667, 0.75      , 0.34408602, 0.55813953, 0.54545455,\n",
       "        0.28977273, 0.23899371, 0.04      , 0.5       , 0.6       ],\n",
       "       [0.66666667, 0.75      , 0.48387097, 0.51162791, 0.54545455,\n",
       "        0.15909091, 0.28930818, 0.44      , 0.45      , 0.4       ],\n",
       "       [0.83333333, 0.25      , 0.20430108, 0.30232558, 0.36363636,\n",
       "        0.09659091, 0.18867925, 0.24      , 0.3       , 0.26666667],\n",
       "       [1.        , 0.625     , 0.4516129 , 0.44186047, 0.27272727,\n",
       "        0.23295455, 0.37106918, 0.32      , 0.7       , 0.36666667],\n",
       "       [0.        , 0.25      , 0.24731183, 0.65116279, 0.45454545,\n",
       "        0.59659091, 0.72327044, 0.4       , 0.2       , 0.33333333],\n",
       "       [1.        , 0.125     , 0.43010753, 0.58139535, 0.54545455,\n",
       "        0.36363636, 0.20125786, 0.64      , 0.35      , 0.43333333],\n",
       "       [0.        , 0.5       , 0.40860215, 0.48837209, 0.18181818,\n",
       "        0.53409091, 0.72327044, 0.58      , 0.6       , 0.66666667],\n",
       "       [1.        , 0.75      , 0.40860215, 0.41860465, 0.31818182,\n",
       "        0.22159091, 0.30188679, 0.32      , 0.7       , 0.66666667],\n",
       "       [0.        , 0.375     , 0.33870968, 0.65116279, 0.54545455,\n",
       "        0.76704545, 0.76100629, 0.54      , 0.5       , 0.73333333],\n",
       "       [0.        , 0.125     , 0.23655914, 0.41860465, 0.13636364,\n",
       "        0.58522727, 0.66037736, 0.34      , 0.25      , 0.53333333],\n",
       "       [0.33333333, 0.25      , 0.43548387, 0.74418605, 0.54545455,\n",
       "        0.40340909, 0.35849057, 0.74      , 0.4       , 0.56666667],\n",
       "       [1.        , 0.625     , 0.2688172 , 0.65116279, 0.54545455,\n",
       "        0.18181818, 0.32075472, 0.04      , 0.3       , 0.33333333],\n",
       "       [1.        , 0.375     , 0.27956989, 0.34883721, 0.40909091,\n",
       "        0.14772727, 0.35220126, 0.52      , 0.3       , 0.26666667],\n",
       "       [0.66666667, 0.        , 0.12365591, 0.3255814 , 0.40909091,\n",
       "        0.30681818, 0.27672956, 0.64      , 0.15      , 0.2       ],\n",
       "       [0.        , 0.25      , 0.43548387, 1.        , 0.68181818,\n",
       "        1.        , 0.79245283, 0.28      , 0.8       , 1.        ],\n",
       "       [1.        , 0.25      , 0.33333333, 0.53488372, 0.59090909,\n",
       "        0.25568182, 0.22012579, 0.24      , 0.6       , 0.66666667],\n",
       "       [0.83333333, 0.5       , 0.3655914 , 0.65116279, 0.81818182,\n",
       "        0.23863636, 0.3836478 , 1.        , 0.4       , 0.53333333],\n",
       "       [0.83333333, 0.25      , 0.32258065, 0.48837209, 0.54545455,\n",
       "        0.30113636, 0.08805031, 0.84      , 0.55      , 0.66666667],\n",
       "       [0.        , 0.75      , 0.48387097, 0.69767442, 0.36363636,\n",
       "        0.75568182, 1.        , 0.44      , 0.7       , 0.86666667],\n",
       "       [0.16666667, 0.75      , 0.32258065, 0.25581395, 0.31818182,\n",
       "        0.46022727, 0.57861635, 0.62      , 0.5       , 0.33333333],\n",
       "       [0.83333333, 0.25      , 0.33333333, 0.79069767, 0.77272727,\n",
       "        0.30113636, 0.20125786, 0.34      , 0.5       , 0.43333333],\n",
       "       [0.33333333, 0.5       , 0.34408602, 0.60465116, 0.54545455,\n",
       "        0.26704545, 0.43396226, 0.42      , 0.6       , 0.73333333],\n",
       "       [0.16666667, 0.25      , 0.2688172 , 0.44186047, 0.36363636,\n",
       "        0.71022727, 0.69811321, 0.16      , 0.5       , 0.33333333],\n",
       "       [0.66666667, 0.5       , 0.30107527, 0.60465116, 0.5       ,\n",
       "        0.26704545, 0.33333333, 0.44      , 0.65      , 0.6       ],\n",
       "       [0.66666667, 0.25      , 0.43010753, 0.72093023, 0.63636364,\n",
       "        0.29545455, 0.06289308, 0.64      , 0.5       , 0.46666667],\n",
       "       [0.        , 0.5       , 0.53225806, 0.6744186 , 0.36363636,\n",
       "        0.60795455, 0.59748428, 0.6       , 0.5       , 0.46666667],\n",
       "       [1.        , 0.25      , 0.21505376, 0.3255814 , 0.54545455,\n",
       "        0.19886364, 0.28930818, 0.        , 0.2       , 0.4       ],\n",
       "       [1.        , 0.125     , 0.33870968, 0.46511628, 0.45454545,\n",
       "        0.41477273, 0.40880503, 0.34      , 0.35      , 0.4       ],\n",
       "       [0.83333333, 0.375     , 0.10752688, 0.37209302, 0.54545455,\n",
       "        0.06818182, 0.35220126, 0.38      , 0.4       , 0.6       ],\n",
       "       [1.        , 0.25      , 0.51612903, 0.65116279, 0.54545455,\n",
       "        0.29545455, 0.48427673, 0.44      , 0.4       , 0.46666667],\n",
       "       [0.16666667, 0.125     , 0.25806452, 0.34883721, 0.27272727,\n",
       "        0.61931818, 0.73584906, 0.16      , 0.6       , 0.43333333],\n",
       "       [0.        , 0.25      , 0.45698925, 0.74418605, 0.68181818,\n",
       "        0.75      , 0.74213836, 0.68      , 0.6       , 0.73333333],\n",
       "       [1.        , 0.125     , 0.57526882, 0.8372093 , 0.86363636,\n",
       "        0.64772727, 0.40880503, 0.44      , 0.4       , 0.73333333],\n",
       "       [0.        , 0.625     , 0.43010753, 0.6744186 , 0.5       ,\n",
       "        0.60227273, 0.82389937, 0.32      , 0.55      , 0.46666667],\n",
       "       [1.        , 0.        , 0.25268817, 0.34883721, 0.63636364,\n",
       "        0.23295455, 0.48427673, 0.24      , 0.3       , 0.53333333],\n",
       "       [0.66666667, 0.625     , 0.40860215, 0.69767442, 0.72727273,\n",
       "        0.30681818, 0.1572327 , 0.44      , 0.55      , 0.6       ],\n",
       "       [0.66666667, 0.5       , 0.32258065, 0.62790698, 0.54545455,\n",
       "        0.31818182, 0.17610063, 0.92      , 0.5       , 0.33333333],\n",
       "       [0.33333333, 0.5       , 0.51612903, 0.46511628, 0.36363636,\n",
       "        0.21022727, 0.22641509, 0.92      , 0.6       , 0.9       ],\n",
       "       [0.33333333, 0.5       , 0.70967742, 0.46511628, 0.18181818,\n",
       "        0.375     , 0.28930818, 0.84      , 0.6       , 0.66666667]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ec10e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
